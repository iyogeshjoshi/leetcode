<h2>Cheatsheets</h2>
<hr />

<p>
  This article will be a collection of cheat sheets that you can use as you
  solve problems and prepare for interviews. You will find:
</p>

<ul>
  <li>Time complexity (Big O) cheat sheet</li>

  <li>General DS/A flowchart (when to use each DS/A)</li>

  <li>Stages of an interview cheat sheet</li>
</ul>

<hr />

<h3 id="time-complexity-big-o-cheat-sheet">
  Time complexity (Big O) cheat sheet
</h3>

<p>
  <img alt="big O chart" src="../Figures/DSA/Chapter_11/big_o.png" />
  <br />
</p>

<p>
  First, let's talk about the time complexity of common operations, split by
  data structure/algorithm. Then, we'll talk about reasonable complexities given
  input sizes.
</p>

<p>
  <strong>Arrays (dynamic array/list)</strong>
</p>

<p>Given <code>n = arr.length</code>,</p>

<ul>
  <li>
    Add or remove element at the end:
    <script type="math/tex; mode=display">
      O(1)
    </script>
    <a
      href="https://stackoverflow.com/questions/33044883/why-is-the-time-complexity-of-pythons-list-append-method-o1"
      target="_blank"
      >amortized</a
    >
  </li>

  <li>
    Add or remove element from arbitrary index:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Access or modify element at arbitrary index:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Check if element exists:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Two pointers:
    <script type="math/tex; mode=display">
      O(n \\cdot k)
    </script>
    , where
    <script type="math/tex; mode=display">
      k
    </script>
    is the work done at each iteration, includes sliding window
  </li>

  <li>
    Building a prefix sum:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Finding the sum of a subarray given a prefix sum:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>
</ul>

<hr />

<p>
  <strong>Strings (immutable)</strong>
</p>

<p>Given <code>n = s.length</code>,</p>

<ul>
  <li>
    Add or remove character:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Access element at arbitrary index:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Concatenation between two strings:
    <script type="math/tex; mode=display">
      O(n + m)
    </script>
    , where
    <script type="math/tex; mode=display">
      m
    </script>
    is the length of the other string
  </li>

  <li>
    Create substring:
    <script type="math/tex; mode=display">
      O(m)
    </script>
    , where
    <script type="math/tex; mode=display">
      m
    </script>
    is the length of the substring
  </li>

  <li>
    Two pointers:
    <script type="math/tex; mode=display">
      O(n \\cdot k)
    </script>
    , where
    <script type="math/tex; mode=display">
      k
    </script>
    is the work done at each iteration, includes sliding window
  </li>

  <li>
    Building a string from joining an array, stringbuilder, etc.:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>
</ul>

<hr />

<p>
  <strong>Linked Lists</strong>
</p>

<p>
  Given
  <script type="math/tex; mode=display">
    n
  </script>
  as the number of nodes in the linked list,
</p>

<ul>
  <li>
    Add or remove element given pointer before add/removal location:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Add or remove element given pointer at add/removal location:
    <script type="math/tex; mode=display">
      O(1)
    </script>
    if doubly linked
  </li>

  <li>
    Add or remove element at arbitrary position without pointer:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Access element at arbitrary position without pointer:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Check if element exists:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Reverse between position <code>i</code> and <code>j</code>:
    <script type="math/tex; mode=display">
      O(j - i)
    </script>
  </li>

  <li>
    Detect a cycle:
    <script type="math/tex; mode=display">
      O(n)
    </script>
    using fast-slow pointers or hash map
  </li>
</ul>

<hr />

<p>
  <strong>Hash table/dictionary</strong>
</p>

<p>Given <code>n = dic.length</code>,</p>

<ul>
  <li>
    Add or remove key-value pair:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Check if key exists:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Check if value exists:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Access or modify value associated with key:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Iterate over all keys, values, or both:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>
</ul>

<blockquote>
  <p>
    Note: the
    <script type="math/tex; mode=display">
      O(1)
    </script>
    operations are constant relative to <code>n</code>. In reality, the hashing
    algorithm might be expensive. For example, if your keys are strings, then it
    will cost
    <script type="math/tex; mode=display">
      O(m)
    </script>
    where
    <script type="math/tex; mode=display">
      m
    </script>
    is the length of the string. The operations only take constant time relative
    to the size of the hash map.
  </p>
</blockquote>

<hr />

<p>
  <strong>Set</strong>
</p>

<p>Given <code>n = set.length</code>,</p>

<ul>
  <li>
    Add or remove element:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Check if element exists:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>
</ul>

<blockquote>
  <p>The above note applies here as well.</p>
</blockquote>

<hr />

<p>
  <strong>Stack</strong>
</p>

<p>
  Stack operations are dependent on their implementation. A stack is only
  required to support pop and push. If implemented with a dynamic array:
</p>

<p>Given <code>n = stack.length</code>,</p>

<ul>
  <li>
    Push element:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Pop element:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Peek (see element at top of stack):
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Access or modify element at arbitrary index:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Check if element exists:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>
</ul>

<hr />

<p>
  <strong>Queue</strong>
</p>

<p>
  Queue operations are dependent on their implementation. A queue is only
  required to support dequeue and enqueue. If implemented with a doubly linked
  list:
</p>

<p>Given <code>n = queue.length</code>,</p>

<ul>
  <li>
    Enqueue element:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Dequeue element:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Peek (see element at front of queue):
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Access or modify element at arbitrary index:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>

  <li>
    Check if element exists:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>
</ul>

<blockquote>
  <p>
    Note: most programming languages implement queues in a more sophisticated
    manner than a simple doubly linked list. Depending on implementation,
    accessing elements by index may be faster than
    <script type="math/tex; mode=display">
      O(n)
    </script>
    , or
    <script type="math/tex; mode=display">
      O(n)
    </script>
    but with a significant constant divisor.
  </p>
</blockquote>

<hr />

<p>
  <strong>Binary tree problems (DFS/BFS)</strong>
</p>

<p>
  Given
  <script type="math/tex; mode=display">
    n
  </script>
  as the number of nodes in the tree,
</p>

<p>
  Most algorithms will run in
  <script type="math/tex; mode=display">
    O(n \\cdot k)
  </script>
  time, where
  <script type="math/tex; mode=display">
    k
  </script>
  is the work done at each node, usually
  <script type="math/tex; mode=display">
    O(1)
  </script>
  . This is just a general rule and not always the case. We are assuming here
  that BFS is implemented with an efficient queue.
</p>

<hr />

<p>
  <strong>Binary search tree</strong>
</p>

<p>
  Given
  <script type="math/tex; mode=display">
    n
  </script>
  as the number of nodes in the tree,
</p>

<ul>
  <li>
    Add or remove element:
    <script type="math/tex; mode=display">
      O(n)
    </script>
    worst case,
    <script type="math/tex; mode=display">
      O(\\log{}n)
    </script>
    average case
  </li>

  <li>
    Check if element exists:
    <script type="math/tex; mode=display">
      O(n)
    </script>
    worst case,
    <script type="math/tex; mode=display">
      O(\\log{}n)
    </script>
    average case
  </li>
</ul>

<p>
  The average case is when the tree is well balanced - each depth is close to
  full. The worst case is when the tree is just a straight line.
</p>

<hr />

<p>
  <strong>Heap/Priority Queue</strong>
</p>

<p>Given <code>n = heap.length</code> and talking about min heaps,</p>

<ul>
  <li>
    Add an element:
    <script type="math/tex; mode=display">
      O(\\log{}n)
    </script>
  </li>

  <li>
    Delete the minimum element:
    <script type="math/tex; mode=display">
      O(\\log{}n)
    </script>
  </li>

  <li>
    Find the minimum element:
    <script type="math/tex; mode=display">
      O(1)
    </script>
  </li>

  <li>
    Check if element exists:
    <script type="math/tex; mode=display">
      O(n)
    </script>
  </li>
</ul>

<hr />

<p>
  <strong>Binary search</strong>
</p>

<p>
  Binary search runs in
  <script type="math/tex; mode=display">
    O(\\log{}n)
  </script>
  in the worst case, where
  <script type="math/tex; mode=display">
    n
  </script>
  is the size of your initial search space.
</p>

<hr />

<p>
  <strong>Miscellaneous</strong>
</p>

<ul>
  <li>
    Sorting:
    <script type="math/tex; mode=display">
      O(n \\cdot \\log{}n)
    </script>
    , where
    <script type="math/tex; mode=display">
      n
    </script>
    is the size of the data being sorted
  </li>

  <li>
    DFS and BFS on a graph:
    <script type="math/tex; mode=display">
      O(n \\cdot k + e)
    </script>
    , where
    <script type="math/tex; mode=display">
      n
    </script>
    is the number of nodes,
    <script type="math/tex; mode=display">
      e
    </script>
    is the number of edges, if each node is handled in
    <script type="math/tex; mode=display">
      O(1)
    </script>
    other than iterating over edges
  </li>

  <li>
    DFS and BFS space complexity: typically
    <script type="math/tex; mode=display">
      O(n)
    </script>
    , but if it's in a graph, might be
    <script type="math/tex; mode=display">
      O(n + e)
    </script>
    to store the graph
  </li>

  <li>
    Dynamic programming time complexity:
    <script type="math/tex; mode=display">
      O(n \\cdot k)
    </script>
    , where
    <script type="math/tex; mode=display">
      n
    </script>
    is the number of states and
    <script type="math/tex; mode=display">
      k
    </script>
    is the work done at each state
  </li>

  <li>
    Dynamic programming space complexity:
    <script type="math/tex; mode=display">
      O(n)
    </script>
    , where
    <script type="math/tex; mode=display">
      n
    </script>
    is the number of states
  </li>
</ul>

<hr />

<h3 id="input-sizes-vs-time-complexity">Input sizes vs time complexity</h3>

<p>
  The constraints of a problem can be considered as hints because they indicate
  an upper bound on what your solution's time complexity should be. Being able
  to figure out the expected time complexity of a solution given the input size
  is a valuable skill to have. In all LeetCode problems and most online
  assessments (OA), you will be given the problem's constraints. Unfortunately,
  you will usually not be explicitly told the constraints of a problem in an
  interview, but it's still good for practicing on LeetCode and completing OAs.
  Still, in an interview, it usually doesn't hurt to ask about the expected
  input sizes.
</p>

<hr />

<p>
  <ins>
    <strong>n &lt;= 10</strong>
  </ins>
</p>

<p>
  The expected time complexity likely has a factorial or an exponential with a
  base larger than <code>2</code> -
  <script type="math/tex; mode=display">
    O(n^2 \\cdot n!)
  </script>
  or
  <script type="math/tex; mode=display">
    O(4^n)
  </script>
  for example.
</p>

<p>
  You should think about backtracking or any brute-force-esque recursive
  algorithm. <code>n &lt;= 10</code> is extremely small and usually
  <strong>any</strong> algorithm that correctly finds the answer will be fast
  enough.
</p>

<hr />

<p>
  <ins>
    <strong>10 &lt; n &lt;= 20</strong>
  </ins>
</p>

<p>
  The expected time complexity likely involves
  <script type="math/tex; mode=display">
    O(2^n)
  </script>
  . Any higher base or a factorial will be too slow (
  <script type="math/tex; mode=display">
    3^{20}
  </script>
  = ~3.5 billion, and
  <script type="math/tex; mode=display">
    20!
  </script>
  is much larger). A
  <script type="math/tex; mode=display">
    2^n
  </script>
  usually implies that given a collection of elements, you are considering all
  subsets/subsequences - for each element, there are two choices: take it or
  don't take it.
</p>

<p>
  Again, this bound is very small, so most algorithms that are correct will
  probably be fast enough. Consider backtracking and recursion.
</p>

<hr />

<p>
  <ins>
    <strong>20 &lt; n &lt;= 100</strong>
  </ins>
</p>

<p>
  At this point, exponentials will be too slow. The upper bound will likely
  involve
  <script type="math/tex; mode=display">
    O(n^3)
  </script>
  .
</p>

<p>
  Problems marked as "easy" on LeetCode usually have this bound, which can be
  deceiving. There may be solutions that run in
  <script type="math/tex; mode=display">
    O(n)
  </script>
  , but the small bound allows brute force solutions to pass (finding the linear
  time solution might not be considered as "easy").
</p>

<p>
  Consider brute force solutions that involve nested loops. If you come up with
  a brute force solution, try analyzing the algorithm to find what steps are
  "slow", and try to improve on those steps using tools like hash maps or heaps.
</p>

<hr />

<p>
  <ins>
    <strong>100 &lt; n &lt;= 1,000</strong>
  </ins>
</p>

<p>
  In this range, a quadratic time complexity
  <script type="math/tex; mode=display">
    O(n^2)
  </script>
  should be sufficient, as long as the constant factor isn't too large.
</p>

<p>
  Similar to the previous range, you should consider nested loops. The
  difference between this range and the previous one is that
  <script type="math/tex; mode=display">
    O(n^2)
  </script>
  is usually the expected/optimal time complexity in this range, and it might
  not be possible to improve.
</p>

<hr />

<p>
  <ins>
    <strong>1,000 &lt; n &lt; 100,000</strong>
  </ins>
</p>

<p>
  <script type="math/tex; mode=display">
    n <= 10^5
  </script>
  is the most common constraint you will see on LeetCode. In this range, the
  slowest acceptable <strong>common</strong> time complexity is
  <script type="math/tex; mode=display">
    O(n \\cdot \\log{}n)
  </script>
  , although a linear time approach
  <script type="math/tex; mode=display">
    O(n)
  </script>
  is commonly the goal.
</p>

<p>
  In this range, ask yourself if sorting the input or using a heap can be
  helpful. If not, then aim for an
  <script type="math/tex; mode=display">
    O(n)
  </script>
  algorithm. Nested loops that run in
  <script type="math/tex; mode=display">
    O(n^2)
  </script>
  are unacceptable - you will probably need to make use of a technique learned
  in this course to simulate a nested loop's behavior in
  <script type="math/tex; mode=display">
    O(1)
  </script>
  or
  <script type="math/tex; mode=display">
    O(\\log{}n)
  </script>
  :
</p>

<ul>
  <li>Hash map</li>

  <li>A two pointers implementation like sliding window</li>

  <li>Monotonic stack</li>

  <li>Binary search</li>

  <li>Heap</li>

  <li>A combination of any of the above</li>
</ul>

<p>
  If you have an
  <script type="math/tex; mode=display">
    O(n)
  </script>
  algorithm, the constant factor can be reasonably large (around 40). One common
  theme for string problems involves looping over the characters of the alphabet
  at each iteration resulting in a time complexity of
  <script type="math/tex; mode=display">
    O(26n)
  </script>
  .
</p>

<hr />

<p>
  <ins>
    <strong>100,000 &lt; n &lt; 1,000,000</strong>
  </ins>
</p>

<p>
  <script type="math/tex; mode=display">
    n <= 10^6
  </script>
  is a rare constraint, and will likely require a time complexity of
  <script type="math/tex; mode=display">
    O(n)
  </script>
  . In this range,
  <script type="math/tex; mode=display">
    O(n \\cdot \\log{}n)
  </script>
  is usually safe as long as it has a small constant factor. You will very
  likely need to incorporate a hash map in some way.
</p>

<hr />

<p>
  <ins>
    <strong>1,000,000 &lt; n</strong>
  </ins>
</p>

<p>
  With huge inputs, typically in the range of
  <script type="math/tex; mode=display">
    10^9
  </script>
  or more, the most common acceptable time complexity will be logarithmic
  <script type="math/tex; mode=display">
    O(\\log{}n)
  </script>
  or constant
  <script type="math/tex; mode=display">
    O(1)
  </script>
  . In these problems, you must either significantly reduce your search space at
  each iteration (usually binary search) or use clever tricks to find
  information in constant time (like with math or a clever use of hash maps).
</p>

<blockquote>
  <p>
    Other time complexities are possible like
    <script type="math/tex; mode=display">
      O(\\sqrt{n})
    </script>
    , but this is very rare and will usually only be seen in very advanced
    problems.
  </p>
</blockquote>

<hr />

<h3 id="sorting-algorithms">Sorting algorithms</h3>

<p>
  All major programming languages have a built-in method for sorting. It is
  usually correct to assume and say sorting costs
  <script type="math/tex; mode=display">
    O(n \\cdot \\log{}n)
  </script>
  , where
  <script type="math/tex; mode=display">
    n
  </script>
  is the number of elements being sorted. For completeness, here is a chart that
  lists many common sorting algorithms and their completeness. The algorithm
  implemented by a programming language varies; for example, Python uses Timsort
  but in C++, the specific algorithm is not mandated and varies.
</p>

<p>
  <img
    alt="sorting algorithm complexities"
    src="../Figures/DSA/Chapter_11/sorting.png"
  />
  <br />
</p>

<blockquote>
  <p>
    Definition of a stable sort from
    <a
      href="https://en.wikipedia.org/wiki/Category:Stable_sorts"
      target="_blank"
      >Wikipedia</a
    >: "Stable sorting algorithms maintain the relative order of records with
    equal keys (i.e. values). That is, a sorting algorithm is stable if whenever
    there are two records R and S with the same key and with R appearing before
    S in the original list, R will appear before S in the sorted list."
  </p>
</blockquote>

<hr />

<h3 id="general-dsa-flowchart">General DS/A flowchart</h3>

<p>
  Here's a flowchart that can help you figure out which data structure or
  algorithm should be used. Note that this flowchart is very general as it would
  be impossible to cover every single scenario.
</p>

<blockquote>
  <p>
    Note that this flowchart only covers methods taught in LICC, and as such
    more advanced algorithms like Dijkstra's is excluded.
  </p>
</blockquote>

<p>
  <img
    alt="data structures and algorithm flowchart"
    src="../Figures/DSA/Chapter_11/flowchart.png"
  />
  <br />
</p>

<hr />

<h3 id="interview-stages-cheat-sheet">Interview stages cheat sheet</h3>

<p>
  The following will be a summary of the "Stages of an interview" article. If
  you have a remote interview, you can print this condensed version and keep it
  in front of you during the interview.
</p>

<p>
  <strong>Stage 1: Introductions</strong>
</p>

<ul>
  <li>
    Have a rehearsed 30-60 second introduction regarding your education, work
    experience, and interests prepared.
  </li>

  <li>Smile and speak with confidence.</li>

  <li>
    Pay attention when the interviewer talks about themselves and incorporate
    their work into your questions later.
  </li>
</ul>

<hr />

<p>
  <strong>Stage 2: Problem statement</strong>
</p>

<ul>
  <li>
    Paraphrase the problem back to the interviewer after they have read it to
    you.
  </li>

  <li>
    Ask clarifying questions about the input such as the expected input size,
    edge cases, and invalid inputs.
  </li>

  <li>
    Quickly walk through an example test case to confirm you understand the
    problem.
  </li>
</ul>

<hr />

<p>
  <strong>Stage 3: Brainstorming DS&amp;A</strong>
</p>

<ul>
  <li>Always be thinking out loud.</li>

  <li>
    Break the problem down: figure out what you need to do, and think about what
    data structure or algorithm can accomplish it with a good time complexity.
  </li>

  <li>
    Be receptive to any comments or feedback from the interviewer, they are
    probably trying to hint you towards the correct solution.
  </li>

  <li>
    Once you have an idea, before coding, explain your idea to the interviewer
    and make sure they understand and agree that it is a reasonable approach.
  </li>
</ul>

<hr />

<p>
  <strong>Stage 4: Implementation</strong>
</p>

<ul>
  <li>
    Explain your decision-making as you implement. When you declare things like
    sets, explain what the purpose is.
  </li>

  <li>
    Write clean code that conforms to your programming language's conventions.
  </li>

  <li>
    Avoid writing duplicate code - use a helper function or for loop if you are
    writing similar code multiple times.
  </li>

  <li>
    If you are stuck, don't panic - communicate your concerns with your
    interviewer.
  </li>

  <li>
    Don't be scared to start with a brute force solution (while acknowledging
    that it is brute force), then improve it by optimizing the "slow" parts.
  </li>

  <li>
    Keep thinking out loud and talk with your interviewer. It makes it easier
    for them to give you hints.
  </li>
</ul>

<hr />

<p>
  <strong>Stage 5: Testing &amp; debugging</strong>
</p>

<ul>
  <li>
    When walking through test cases, keep track of the variables by writing at
    the bottom of the file, and continuously update them. Condense trivial parts
    like creating a prefix sum to save time.
  </li>

  <li>
    If there are errors and the environment supports running code, put print
    statements in your algorithm and walk through a small test case, comparing
    the expected value of variables and the actual values.
  </li>

  <li>
    Be vocal and keep talking with your interviewer if you run into any
    problems.
  </li>
</ul>

<hr />

<p>
  <strong>Stage 6: Explanations and follow-ups</strong>
</p>

<p>Questions you should be prepared to answer:</p>

<ul>
  <li>Time and space complexity, average and worst case.</li>

  <li>Why did you choose this data structure, algorithm, or logic?</li>

  <li>
    Do you think the algorithm could be improved in terms of complexity? If they
    ask you this, then the answer is <em>usually</em> yes, especially if your
    algorithm is slower than
    <script type="math/tex; mode=display">
      O(n)
    </script>
    .
  </li>
</ul>

<hr />

<p>
  <strong>Stage 7: Outro</strong>
</p>

<ul>
  <li>Have questions regarding the company prepared.</li>

  <li>
    Be interested, smile, and ask follow-up questions to your interviewer's
    responses.
  </li>
</ul>

<hr />
